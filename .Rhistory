z_all <- matrix(z_all, nrow = 2, ncol = 3)
z_all
x_sq$residuals
bribe_data
r <- apply(bribe_data, 1, sum)
c <- apply(bribe_data, 2, sum)
r
bribe_data <- matrix(c(14, 6, 7, 7, 7, 1), nrow = 2, ncol = 3, byrow = FALSE)
rownames(bribe_data) <- c("Upper class", "Lower class")
colnames(bribe_data) <- c("Not stopped", "Bribe requested", "Stopped")
bribe_data
bribe_data <- matrix(c(14, 6, 7, 7, 7, 1), nrow = 2, ncol = 3, byrow = TRUE)
rownames(bribe_data) <- c("Upper class", "Lower class")
colnames(bribe_data) <- c("Not stopped", "Bribe requested", "Stopped")
bribe_data
r <- apply(bribe_data, 1, sum)
c <- apply(bribe_data, 2, sum)
r
fe_all <- numeric()
chisq <- 0
fe <- 0
for (i in seq(1:nrow(bribe_data))) {
for (j in seq(1:ncol(bribe_data))) {
fe <- (c[j] * r[i]) / sum(bribe_data)
chisq <- chisq + ((bribe_data[i, j] - fe) ^ 2 / fe)
fe_all <- c(fe_all, fe)
}}
print(fe_all)
print(chisq)
# check chi-squre value
chisq.test(bribe_data)
p_value = pchisq(chisq, df = (nrow(bribe_data)-1) * (ncol(bribe_data)-1), lower.tail=FALSE)
p_value <= 0.1
fe_all <- matrix(fe_all, nrow = 2, ncol = 3)
print(fe_all)
print(chisq)
z <- 0
z_all <- numeric()
for (i in seq(1:nrow(bribe_data))) {
for (j in seq(1:ncol(bribe_data))) {
z = (bribe_data[i,j] - fe_all[i, j]) ^ 2 /
(fe_all[i,j] * (1- (r[i] / sum(bribe_data))) * ( 1- (c[j] / sum(bribe_data))))
z_all <- c(z_all, z)
}}
?matrix
fe_all <- matrix(fe_all, nrow = 2, ncol = 3, byrow = TRUE)
print(fe_all)
print(chisq)
# check chi-squre value
chisq.test(bribe_data)
x_sq <- chisq.test(bribe_data)$statistic
chisq == x_sq$statistic
chisq == x_sq$statistic
p_value = pchisq(chisq, df = (nrow(bribe_data)-1) * (ncol(bribe_data)-1), lower.tail=FALSE)
p_value <= 0.1
z <- 0
z_all <- numeric()
for (i in seq(1:nrow(bribe_data))) {
for (j in seq(1:ncol(bribe_data))) {
z = (bribe_data[i,j] - fe_all[i, j]) ^ 2 /
(fe_all[i,j] * (1- (r[i] / sum(bribe_data))) * ( 1- (c[j] / sum(bribe_data))))
z_all <- c(z_all, z)
}}
z_all <- matrix(z_all, nrow = 2, ncol = 3, byrow = TRUE)
z_all
bribe_data
print(fe_all)
v <-(6-83571)/sqrt(6*(1-(27/42))*(1-(15/42)))
v
v <-(6-8.3571)/sqrt(6*(1-(27/42))*(1-(15/42)))
v
z <- 0
z_all <- numeric()
for (i in seq(1:nrow(bribe_data))) {
for (j in seq(1:ncol(bribe_data))) {
z = (bribe_data[i,j] - fe_all[i, j]) /
sart(fe_all[i,j] * (1- (r[i] / sum(bribe_data))) * ( 1- (c[j] / sum(bribe_data))))
z_all <- c(z_all, z)
}}
for (i in seq(1:nrow(bribe_data))) {
for (j in seq(1:ncol(bribe_data))) {
z = (bribe_data[i,j] - fe_all[i, j]) /
sqrt(fe_all[i,j] * (1- (r[i] / sum(bribe_data))) * ( 1- (c[j] / sum(bribe_data))))
z_all <- c(z_all, z)
}}
z_all <- matrix(z_all, nrow = 2, ncol = 3, byrow = TRUE)
z_all
v <-(6-8.3571)/sqrt(6*(1-(27/42))*(1-(15/42)))
v
x_sq$residuels
x_sq$residuel
x_sq$residule
x_sq$residul
x_sq$residual
x_sq$residuals
std_resid <- residuals(x_sq, type = "standardized")
std_resid <- residuals(x_sq, type = "standardized")
z <- 0
z_all <- numeric()
for (i in seq(1:nrow(bribe_data))) {
for (j in seq(1:ncol(bribe_data))) {
z = (bribe_data[i,j] - fe_all[i, j]) /
sqrt(fe_all[i,j] * (1- (r[i] / sum(bribe_data))) * ( 1- (c[j] / sum(bribe_data))))
z_all <- c(z_all, z)
}}
z_all
z_all <- matrix(z_all, nrow = 2, ncol = 3, byrow = TRUE)
z_all
fe_all
v <-(bribe_data[1,2]-fe_all[1,2])/sqrt(bribe_data[1,2]*(1-(27/42))*(1-(15/42)))
v
v <-(bribe_data[1,2]-fe_all[1,2])/sqrt(bribe_data[1,2]*(1-(27/42))*(1-(13/42)))
v
v <-(bribe_data[1,2]-fe_all[1,2])/sqrt(fe_all[1,2]*(1-(27/42))*(1-(13/42)))
v
std_resid <- residuals(x_sq, type = "standardized")
x_sq
x_sq <- chisq.test(bribe_data)
x_sq <- chisq.test(bribe_data)
chisq == x_sq$statistic
x_sq
std_resid <- residuals(x_sq, type = "standardized")
std_resid
z_all
x_sq
ls(x_sq)
x_sq$residuals
fe_all[1,2]
r[1]
r[1]/42
c[2]/42
1-(r[1]/42)
1-(c[2]/42)
8.357143 * 0.3571429 * 0.6904762
sqrt(8.357143 * 0.3571429 * 0.6904762 )
1.43557 ^ 2
6-8.357143
-2.357143 / 1.43557
?residuals
-2.357143/1
x_sq$stdres
print(z_all)
# check standardized residuals
x_sq$stdres
df <- df["https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/women.csv]
head(df)
df <- df("https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/women.csv)
df <- read.csv("https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/women.csv)
head(df)
df <- read.csv("https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/women.csv")
df <- read.csv("https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/women.csv")
head(df)
view(df)
View(df)
plot(df$reserved, df$water)
fac_res <- factor(df$reserved)
fac_res
plot(fac_res, df$water)
View(df)
lm(reserved~water, data = df)
summary(lm(reserved~water, data = df))
# Get working directory
getwd()
# Set working directory
setwd("/Users/poisson/Documents/GitHub/Fork_Statsl Fall2023")
getwd()
if(!require(wbstats)){
install.packages("wbstats")
library(wbstats)}
if(!require(tidyverse)){
install.packages("tidyverse")
library(tidyverse)}
if(!require(ggplot2)){
install.packages("ggplot2")
library(ggplot2)}
if(!require(stargazer)){
install.packages("stargazer")
library(stargazer)}
wb <- wb(country=c("AF","BRA","ITA","NGA","SWE","UGA"),
indicator=c("NY.GDP.PCAP.CD", # GDP per capita (current US$)
"SP.POP.TOTL", # Population, total
"SE.SEC.ENRR", #  School enrollment, secondary (% gross)
"SH.DYN.MORT"), # Mortality rate, under-5 (per 1,000 live births)
startdate = 2000, enddate = 2020)
wb_re <- reshape(wb[, c("country","iso3c","date","indicatorID","value")], # df
timevar = "indicatorID", # New columns
idvar = c("country","date","iso3c"), # Identifiers for rows
direction = "wide")
# Load Quality of Government data
qog <- read_csv("https://www.qogdata.pol.gu.se/data/qog_bas_ts_jan23.csv")
# Merge
df <- merge(wb_re, # Left df
qog[, c("ccodealp","year","bmr_dem")], # Right df
by.x=c("date","iso3c"), # Merge variables in left
by.y=c("year","ccodealp"), # Merge variables in right
all.x=TRUE, # Merge operation, only keep left
sort=FALSE) # Do not sort observations
View(wb)
# Reshape data from long to wide (put rows in columns)
wb_re <- reshape(wb[, c("country","iso3c","date","indicatorID","value")], # df
timevar = "indicatorID", # New columns
idvar = c("country","date","iso3c"), # Identifiers for rows
direction = "wide")
# Load data from World Bank API
wb <- wb(country=c("AF","BRA","ITA","NGA","SWE","UGA"),
indicator=c("NY.GDP.PCAP.CD", # GDP per capita (current US$)
"SP.POP.TOTL", # Population, total
"SE.SEC.ENRR", #  School enrollment, secondary (% gross)
"SH.DYN.MORT"), # Mortality rate, under-5 (per 1,000 live births)
startdate = 2000, enddate = 2020)
# Reshape data from long to wide (put rows in columns)
wb_re <- reshape(wb[, c("country","iso3c","date","indicatorID","value")], # df
timevar = "indicatorID", # New columns
idvar = c("country","date","iso3c"), # Identifiers for rows
direction = "wide")
# Load Quality of Government data
qog <- read_csv("https://www.qogdata.pol.gu.se/data/qog_bas_ts_jan23.csv")
# Merge
df <- merge(wb_re, # Left df
qog[, c("ccodealp","year","bmr_dem")], # Right df
by.x=c("date","iso3c"), # Merge variables in left
by.y=c("year","ccodealp"), # Merge variables in right
all.x=TRUE, # Merge operation, only keep left
sort=FALSE) # Do not sort observations
names(df)
names(df)[4] <- "gdp_per_cap"
names(df)[5] <- "pop_size"
names(df)[6] <- "sec_enrol"
names(df)[7] <- "mort"
names(df)[8] <- "democracy"
# Save df
write.csv(df, "datasets/df_income_mortality.csv")
# Load df
df <- read_csv("datasets/df_income_mortality.csv")
# Get working directory
getwd()
# Set working directory
setwd("/Users/poisson/Documents/GitHub/Fork_Statsl Fall2023")
getwd()
# Agenda
# (a.) Gathering data
# (b.) Data wrangling
# (c.) Descriptive analysis
# (d.) Regression analysis
# Research questions:
# Is there a relationship between income and child mortality?
# Install and load packages
# Adopted from: https://stackoverflow.com/questions/4090169/elegant-way-to-check-for-missing-packages-and-install-them
if(!require(wbstats)){
install.packages("wbstats")
library(wbstats)}
if(!require(tidyverse)){
install.packages("tidyverse")
library(tidyverse)}
if(!require(ggplot2)){
install.packages("ggplot2")
library(ggplot2)}
if(!require(stargazer)){
install.packages("stargazer")
library(stargazer)}
# (a.) Gathering data ----------
# What is an API?
# https://medium.com/geekculture/a-beginners-guide-to-apis-9aa7b1b2e172
# Load data from World Bank API
wb <- wb(country=c("AF","BRA","ITA","NGA","SWE","UGA"),
indicator=c("NY.GDP.PCAP.CD", # GDP per capita (current US$)
"SP.POP.TOTL", # Population, total
"SE.SEC.ENRR", #  School enrollment, secondary (% gross)
"SH.DYN.MORT"), # Mortality rate, under-5 (per 1,000 live births)
startdate = 2000, enddate = 2020)
# Api is conmmunicator between you and database
# every data providers has different type of data
# Data formats--Wide and long
# https://www.statology.org/long-vs-wide-data/
# Reshape data from long to wide (put rows in columns)
wb_re <- reshape(wb[, c("country","iso3c","date","indicatorID","value")], # df
timevar = "indicatorID", # New columns
idvar = c("country","date","iso3c"), # Identifiers for rows
direction = "wide")
View(wb_re)
# Load Quality of Government data
qog <- read_csv("https://www.qogdata.pol.gu.se/data/qog_bas_ts_jan23.csv")
# How can we combine data from different sources?
# https://guides.nyu.edu/quant/merge
# Merge
df <- merge(wb_re, # Left df
qog[, c("ccodealp","year","bmr_dem")], # Right df
by.x=c("date","iso3c"), # Merge variables in left
by.y=c("year","ccodealp"), # Merge variables in right
all.x=TRUE, # Merge operation, only keep left
sort=FALSE) # Do not sort observations
# Rename columns
names(df)
names(df)[4] <- "gdp_per_cap"
names(df)[5] <- "pop_size"
names(df)[6] <- "sec_enrol"
names(df)[7] <- "mort"
names(df)[8] <- "democracy"
View(df)
# Save df
write.csv(df, "datasets/df_income_mortality.csv")
# (b.) Data wrangling -------
# Load df
df <- read_csv("datasets/df_income_mortality.csv")
View(df)
# Get unique countries in df
df_uni <- select(df, country) # Select variable
df_uni <- distinct(df_uni, country) # Get unique values
df_uni
# Get unique countries in df, using the pipe
df %>%
select(country) %>%
distinct(country)
# Filter (subset is base R)
df_s <- filter(df, country %in% c("Afghanistan","Italy"))
df_s
# Get the mean income and max child mortality for each year
df_grouped <- group_by(df, date) # Group by year
df_mean_inc <- summarize(df_grouped,
n=n(), # Counts
mean_inc=mean(gdp_per_cap), # Mean
max_mort=max(mort)) # Max
df_mean_inc
# Check if df has missing values
sum(is.na(df$gdp_per_cap))
sum(is.na(df$mort))
# Replace missing values
# Option I: Replace missing values with zero, but be careful!
df_na <- df %>% replace(is.na(.), 0)
# Option II: Replace missing values with mean
df_na <- df # Copy
?replace_na
df_na$gdp_per_cap <- replace_na(data=df_na$gdp_per_cap,
replace=mean(df_na$gdp_per_cap, # Value to replace NA with
na.rm = TRUE))
# Step by step:
mean(df_na$gdp_per_cap, na.rm = TRUE)
# Option III: Replace missing values with group mean
df_na <- group_by(df_na, country) # Group
df_na <- mutate(df_na, # Replace with mean if value is missing
sec_enrol = ifelse(is.na(sec_enrol),
mean(sec_enrol, na.rm = TRUE),
sec_enrol))
# Step by step:
# ifelse(test, yes, no)
# --> if is.na is True, replace with mean,
# if is.na is False, replace with value
# Re-coding variables, in Base R
# Create categorical income variable
df_na$income_cat <- 0 # Create empty variable
summary(df_na$gdp_per_cap) # Check quantile
df_na$income_cat[df_na$gdp_per_cap>756.8] <- 1 # Place step by step
df_na$income_cat[df_na$gdp_per_cap>3171.6] <- 2
df_na$income_cat[df_na$gdp_per_cap>31768.3] <- 3
# Convert into factor
typeof(df_na$income_cat)
df_na$income_cat <- factor(df_na$income_cat,
labels = c("low","medium_low","medium_high","high"))
# Re-coding variables, in tidyverse
# Create categorical income variable
quantile(df_na$gdp_per_cap) # Check quantiles
df_na <- df_na # Copy
df_na <- mutate(df_na, income_cat2=cut(gdp_per_cap,
breaks=quantile(df_na$gdp_per_cap),
labels=c("low","medium_low","medium_high","high")))
typeof(df_na$income_cat)
# Step by step:
cut(df_na$gdp_per_cap,breaks=c(0,600,800,Inf)) # Define breaks
cut(df_na$gdp_per_cap,breaks=quantile(df_na$gdp_per_cap)) # Use quantiles as breaks
cut(df_na$gdp_per_cap,breaks=quantile(df_na$gdp_per_cap),labels=c("low","medium_low","medium_high","high")) # Add labels
# Drop missing values
df <- df[complete.cases(df), ]
# Scatter plot
scatter <-
ggplot(data = df_na, # --> data
mapping = aes(x = gdp_per_cap,
y = mort)) +  # --> aesthetic mapping
geom_point() # --> geometric object, scatter plot
# Print plot object
scatter
# Scatter plot, log-transform income
hist(df_na$gdp_per_cap)
hist(log(df_na$gdp_per_cap))
# Scatter plot
scatter <-
ggplot(data = df_na,
mapping = aes(x = log(gdp_per_cap), # log-transform
y = mort)) +
geom_point()
scatter
scatter <-
ggplot(data = df_na,
mapping = aes(x = log(gdp_per_cap), # log-transform
y = mort,
size = sec_enrol)) +
geom_point()
scatter
# Fit model
model <- lm(mort ~ gdp_per_cap, data=df_na)
summary(model)
df_na$gdp_per_cap_1000 <- df_na$gdp_per_cap/1000
model <- lm(mort ~ gdp_per_cap_1000, data=df_na)
summary(model)
# Export Latex table
stargazer(model)
model <- lm(mort ~ democracy, data=df_na)
summary(model)
setwd("/Users/poisson/Documents/GitHub/Fork_Statsl Fall2023")
getwd()
rm(list=ls())
# Question 1: Political Science
# (a) Calculate the Ï‡^2 test statistic by hand/manually
bribe_data <- matrix(c(14, 6, 7, 7, 7, 1), nrow = 2, ncol = 3, byrow = TRUE)
rownames(bribe_data) <- c("Upper class", "Lower class")
colnames(bribe_data) <- c("Not stopped", "Bribe requested", "Stopped")
bribe_data
r <- apply(bribe_data, 1, sum)
c <- apply(bribe_data, 2, sum)
r
fe_all <- numeric()
chisq <- 0
fe <- 0
for (i in seq(1:nrow(bribe_data))) {
for (j in seq(1:ncol(bribe_data))) {
fe <- (c[j] * r[i]) / sum(bribe_data)
chisq <- chisq + ((bribe_data[i, j] - fe) ^ 2 / fe)
fe_all <- c(fe_all, fe)
}}
fe_all <- matrix(fe_all, nrow = 2, ncol = 3, byrow = TRUE)
print(fe_all)
print(chisq)
# check chi-squre value
chisq.test(bribe_data)
x_sq <- chisq.test(bribe_data)
chisq == x_sq$statistic
# (b) Now calculate the p-value from the test statistic you just created
p_value = pchisq(chisq, df = (nrow(bribe_data)-1) * (ncol(bribe_data)-1), lower.tail=FALSE)
p_value <= 0.1
# (c) Calculate the standardized residuals for each cell a
z <- 0
z_all <- numeric()
for (i in seq(1:nrow(bribe_data))) {
for (j in seq(1:ncol(bribe_data))) {
z = (bribe_data[i,j] - fe_all[i, j]) /
sqrt(fe_all[i,j] * (1- (r[i] / sum(bribe_data))) * ( 1- (c[j] / sum(bribe_data))))
z_all <- c(z_all, z)
}}
z_all <- matrix(z_all, nrow = 2, ncol = 3, byrow = TRUE)
print(z_all)
# check standardized residuals
x_sq$stdres
df <- read.csv("https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/women.csv")
head(df)
fac_res <- factor(df$reserved)
fac_res
plot(fac_res, df$water)
lm(reserved~water, data = df)
model <- lm(reserved~water, data = df)
# Scatter plot
scatter <-
ggplot(data = df_na, # --> data
mapping = aes(x = gdp_per_cap,
y = mort)) +  # --> aesthetic mapping
geom_point() # --> geometric object, scatter plot
scatter <-
ggplot(data = df,
mapping = aes(x = reserved), # log-transform
y = water)) +
scatter <-
ggplot(data = df,
mapping = aes(x = reserved),
y = water) +
geom_point()
scatter
rlang::last_trace()
scatter <-
ggplot(data = df,
mapping = aes(x = reserved),
y = water) +
geom_point()
scatter
scatter <- ggplot(data = df,
mapping = aes(x = reserved, y = water)) +
geom_point()
scatter
## Fit model
model <- lm(reserved~water, data = df)
model
summary(model)
print(chisq)
print(fe_all)
chisq == x_sq$statistic
x_sq <- chisq.test(bribe_data)
# check chi-squre value
chisq.test(bribe_data)
p_value <= 0.1
p_value = pchisq(chisq, df = (nrow(bribe_data)-1) * (ncol(bribe_data)-1), lower.tail=FALSE)
p_value
p_value <= 0.1
print(z_all)
# check standardized residuals
x_sq$stdres
summary(model)
## Fit model
model <- lm(water~fac_res, data = df)
model
summary(model)
reserved <- factor(df$reserved)
## Fit model
model <- lm(water~reserved, data = df)
summary(model)
head(df)
